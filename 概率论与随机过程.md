# 概率论与随机过程

## 一、概率与分布

### 1.1 条件概率与独立事件

1. 条件概率：已知事件$A$发生的条件$B$下发生的概率，记作 $P(B|A)$，它等于事件$AB$的概率相对于事件$A$的概率，即：$P(B|A)=\frac{P(AB)}{P(A)}$。其中必须有$P(A > 0)$。

2. 条件概率分布的链式法则：对于 $n$个随机变量$\Chi_1,\Chi_2, \cdots, \Chi_n$，有：
   $$
   P(\Chi_1,\Chi_2, \cdots, \Chi_n) = P(\Chi_1)\prod_{i=2}^{n}P(\Chi_i|\Chi_1, \cdots, \Chi_{i-1})
   $$

3. 两个随机变量$\Chi, Y$相互独立的数学描述：$P(\Chi,Y)=P(\Chi)P(Y)$，记做：$\Chi \perp Y$
4. 两个随机变量$\Chi, Y$关于随机变量$Z$条件独立的数学描述：$P(\Chi,Y|Z)=P(\Chi|Z)P(Y|Z)$，记做：$\Chi \perp Y|Z$

### 1.2  联合概率分布

1. 定义$X$和$Y$的联合概率分布为：$P(a,b)=P\{X \leq{a} , Y \leq {b}\},-\infty < a,b < +\infty$。

   - $X$的分布可以从联合分布中得到：
     $$
     P_{X}(a) = P(X \leq {a})=P(X \leq{a},Y \leq{\infty}) = P(a. \infty), -\infty < a < +\infty
     $$

   - $Y$的分布可以从联合分布中得到：
     $$
     P_{Y}(b)=P\{Y \leq{b})=P(X \leq{\infty}, Y \leq{b})\}=P(\infty, b),-\infty < b < +\infty
     $$

2. 当$X$和$Y$都是离散型随机变量时，定义$X$和$Y$的联合概率质量函数为：$p(x,y)=P(X=x, Y=y)$，则$X$和$Y$的概率质量函数分布为：
   $$
   p_{X}(x)=\sum_{y}p(x,y) \\ 
   p_{Y}(y)=\sum_{x}p(x, y)
   $$

3. 当$X$和$Y$联合地连续时，即存在函数$P(x,y)$，使得对于所有的实数集合$\mathbb{A}$和$\mathbb{B}$满足：
   $$
   P(X \in{\mathbb{A}, y\in{\mathbb{B}}})=\int_{\mathbb{A}}\int_{\mathbb{B}}p(x,y)dxdy
   $$
   

   则函数 $p(x,y)$称为$X$和$Y$的概率密度函数。

   - 联合分布为：$P(a, b)=P(X \leq{a},Y \leq{b})=\int_{- \infty}^{a}\int_{-\infty^{b}p(x,y)dxdy}$。

   - $X$和$Y$的分布函数以及概率密度函数分别为：
     $$
     P_{X}(a)=\int_{-\infty}^{a}\int_{-\infty}^{+\infty}p(x,y)dxdy=\int_{-\infty}^{a}p_{X}(x)dx \\
     p_{Y}(b) = \int_{-\infty}^{+\infty}\int_{-\infty}^{b}p(x,y)dxdy=\int_{-\infty}^{b}p_{Y}(y)dy \\
     p_{X}(x)= \int_{-\infty}^{+\infty}p(x,y)dy \\
     p_{Y}(y) = \int_{-\infty}^{+\infty}p(x,y)dx
     $$
     

## 二、期望和方差

### 2.1 期望

1. 期望描述了随机变量的平均情况，衡量了随机变量 $X$的均值。它是概率分布的泛函（函数的函数）。
   - 离散型随机变量$X$的期望：$\mathbb{E}[X]=\sum_{i=1}^{\infty}x_ip_i$。若右侧级数不收敛，则期望不存在。
   - 连续性随机变量$X$的期望：$\mathbb{E}[X]=\int_{-\infty}^{\infty}xp(x)dx$ 。若右侧极限不收敛，则期望不存在。

2. 定理：对于随机变量$X$，设 $Y=g(X)$也为随机变量，$g(\centerdot)$是连续函数。

   - 若$X$为离散型随机变量，若$Y$的期望存在，则：$\mathbb{E}[Y]=\mathbb{E}[g(X)]=\sum_{i=1}^{\infty}g(x_i)p_i$。也记做：$\mathbb{E}_{x\sim P(X)}[g(X)]=\sum_{x}{g(x)p(x)}$。
   - 若$X$为连续型随机变量，若$Y$的期望存在，则 ：$\mathbb{E}[Y]=\mathbb{E}[g(X)]=\int_{-\infty}^{\infty}g(x)p(x)dx$。也记做：$\mathbb E_{X \sim{p(X)}}[g(X)]=\int{g(x)p(x)dx}$。

     该定理的意义在于：当求$\mathbb{E}(Y)$时，不必计算出$Y$的分布，只需要利用$X$的分布即可。

   该定理可以推广至两个或两个以上随机变量的情况。对于随机变量$X,Y$，假设$Z=g(X,Y)$也是随机变量，$g(\centerdot)$为连续函数，则有：$\mathbb{E}[Z]=E[g(X,Y)]=\int_{-\infty}^{\infty}g(x,y)p(x,y)dxdy$。也记做$\mathbb{E}_{X,Y \sim P(X,Y)}[g(X,Y)]\int g(x,y)p(x,y)dxdy$。也记做：$\mathbb{E}_{X,Y}[g(X,Y)]=\int g(x,y)p(x,y)dxdy$。

3. 期望性质：
   - 常数的期望就是常数本身。
   - 对常数$C$有：$\mathbb{E}[CX]=C\mathbb{E}(X)$ 
   - 对两个随机变量$X,Y$，有$\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]$。该结论可以推广到任意有限个随机变量之和的情况。
   - 对两个相互独立的随机变量，有：$\mathbb{E}[XY]=\mathbb{E}[X]\mathbb{E}[Y]$。该结论可以推广到任意有限个相互独立的随机变量之积的情况。

### 2.2 方差

1. 对随机变量$X$，若$\mathbb{E}[(X-\mathbb[X])^2]$存在，则称它为$X$的方差，记作 $Var[X]$。$X$ 的标准差为方差的开平方。即：
   $$
   Var[X]=\mathbb{E}[(X-\mathbb{E}[X])^2] \\
   \sigma = \sqrt{Var[X]}
   $$

   - 方差度量了随机变量$X$与期望值偏离的程度，衡量了$X$取值分散程度的一个尺度。
   - 由于绝对值$|X-\mathbb{E}[X]|$带有绝对值，不方便运算，因此采用平方来计算。又因为$(X-\mathbb{E}[X])^2$是一个随机变量，因此对它取期望，即得$X$与期望值偏离的均值。

2. 根据定义可知：
   $$
   Var[X]=\mathbb{E}[(X-\mathbb{E}[x])^2] = \mathbb{E}[x^2] -(\mathbb{E}[x])^2 \\
   Var[f(X)]=\mathbb{E}[(f(X)-\mathbb{E}[f(X)])^2]
   $$
   

